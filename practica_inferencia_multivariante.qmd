---
title: "Ejercicios de estimación y contrastes multivariantes"
subtitle: "23217- Análisis de Datos para el GMAT"
autor: "Paula G Ferrer, Josep Cifre y Marc Escandell"
date: today
format:
  html:
    theme: lumen
    toc: true
    toc-depth: 3
Rendering:
    embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Problema 1

Una empresa de marketing realizó una encuesta a 500 clientes para conocer sus preferencias entre tres productos: A, B y C. Los resultados fueron los siguientes:

-   Producto A: 200 clientes lo prefieren.
-   Producto B: 150 clientes lo prefieren.
-   Producto C: 150 clientes lo prefieren.

(a) Define un modelo multinomial para las preferencias de los clientes. Estima los parámetros del modelo.

    #### Respuesta 1.a

(b) Utiliza el modelo para estimar la probabilidad de que en una muestra de 10 clientes, 5 prefieran el producto A, 3 prefieran el producto B y 2 prefieran el producto C. Utiliza R para hacer los cálculos.

    #### Respuesta 1.b

(c) Simula 1000 muestras aleatorias de tamaño 10 y calcula cuántas veces ocurre cada combinación de preferencias. Calcula la frecuencia con la que aparece cada combinación de preferencias en las simulaciones. Compara la probabilidad teórica calculada en el apartado b con la frecuencia observada en las simulaciones.

    #### Respuesta 1.c

# Problema 2

Una organización ambiental está interesada en modelar los niveles de contaminación en una ciudad, tomando en cuenta dos variables: la cantidad de emisiones industriales (en toneladas) y la densidad de tráfico (número de vehículos por kilómetro cuadrado). Se ha tomado una muestra de $n=5$ días en los que se midieron estas variables, junto con los niveles de contaminación registrados (en partículas por millón). Los datos son los siguientes:

| Contaminación (Y) | Emisiones Industriales (X1) | Densidad de Tráfico (X2) |
|-------------------|-----------------------------|--------------------------|
| 50                | 200                         | 150                      |
| 60                | 240                         | 170                      |
| 55                | 220                         | 160                      |
| 52                | 210                         | 155                      |
| 58                | 230                         | 165                      |

Supón que los datos siguen un modelo de regresión multivariante del tipo:

$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon
$$

Donde $Y$ es el vector de niveles de contaminación, $X_1$ es el vector de emisiones industriales, $X_2$ es la densidad de tráfico, y $\epsilon$ es el término de error.

Calcula la función de score e interpreta el resultado en este contexto ambiental

#### Respuesta 2

El vector de observaciones $Y \in \mathbb{R}^n$ y la matriz de diseño

$$ X =
\begin{bmatrix}
1 & X_{11} & X_{12}\\
\vdots & \vdots & \vdots\\
1 & X_{n1} & X_{n2}
\end{bmatrix}
\qquad 
\beta =\begin{bmatrix}
\beta_0\\ \beta_1\\ \beta_2
\end{bmatrix}$$

Recordemos que la función scorela definimos en los apuntes como:

$$
z(X, \theta) = \sum_{i=1}^n \frac{\partial}{\partial \theta} \log f(x_i, \theta)
$$

La función de verosimilitud bajo normalidad es: $$
L(\beta, \sigma^2) = (2\pi\sigma^2)^{-n/2} \exp\left( -\frac{1}{2\sigma^2}(Y-X\beta)^t (Y-X\beta) \right), $$ y su log-verosimilitud: $$ 
\ell(\beta, \sigma^2) = -\frac{n}{2}\log(2\pi\sigma^2) -\frac{1}{2\sigma^2}(Y-X\beta)^t (Y-X\beta). $$

El score es el gradiente de la log-verosimilitud respecto a los parámetros:

$$ z(\beta,\sigma^2) =
\begin{pmatrix}
\dfrac{\partial\ell}{\partial\beta}\\[6pt]
\dfrac{\partial\ell}{\partial\sigma^2}
\end{pmatrix}$$

Calculando las derivadas:

$$
\frac{\partial\ell}{\partial\beta} = \frac{1}{\sigma^2} X^t (Y - X\beta), 
$$

$$
\frac{\partial\ell}{\partial\sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}(Y-X\beta)^t (Y-X\beta). $$

Por tanto, la funcion score es:

$$ 
z(\beta,\sigma^2)
=\begin{pmatrix}
\dfrac{1}{\sigma^2}X^t(Y - X\beta)\\[8pt]
-\dfrac{n}{2\sigma^2} + \dfrac{(Y-X\beta)^t(Y-X\beta)}{2\sigma^4}
\end{pmatrix}.
$$

Calculemos la matriz de la información de Fisher:

$$
F(\theta) = -E[ (\frac{\partial ^2\log L(\theta)}{\partial \theta \partial \theta^t})]
$$

Lo metemos en R:

```{r}
# Datos
Y  <- c(50, 60, 55, 52, 58)
X1 <- c(200, 240, 220, 210, 230)
X2 <- c(150, 170, 160, 155, 165)
n  <- length(Y)

# Matriz de diseño
X <- cbind(1, X1, X2)

# función de log-verosimilitud (apunts)
logVeros <- function(beta, sigma2) {
  # beta: vector (beta0, beta1, beta2)
  # sigma2: varianza sigma^2
  # devuelve log L(beta, sigma^2)
  - (n/2)*log(2*pi*sigma2) -
    (1/(2*sigma2)) * t(Y - X %*% beta) %*% (Y - X %*% beta)
}

# función score (gradiente de la log-verosimilitud)
score <- function(beta, sigma2) {
  # según el temario:
  # s_beta = (1/sigma^2) X'(Y - X*beta)
  # s_sigma2 = -(n/(2sigma^2)) + (1/(2sigma^4))(Y - X*beta)'(Y - X*beta)
  
  resid <- Y - X %*% beta
  s_beta <- (1/sigma2) * t(X) %*% resid
  s_sigma2 <- -n/(2*sigma2) + as.numeric((t(resid) %*% resid) / (2*sigma2^2))
  
  return(list(s_beta = s_beta, s_sigma2 = s_sigma2))
}

# Comprobamos la función con valores iniciales (p.ej. beta = 0, sigma2 = 1)
beta0 <- matrix(c(0, 0, 0), ncol=1)
sigma20 <- 1
score(beta0, sigma20)

# Comprobamos colinealidad (por si X'X es singular)
det(t(X) %*% X)  # Si da 0, hay colinealidad perfecta

# Como el determinante da 0, el modelo está mal condicionado
# pero seguimos el procedimiento teórico igualmente:

#ESTA MIERDA FALLA
beta_hat <- solve(t(X) %*% X, t(X) %*% Y)  # fórmula teórica
res <- Y - X %*% beta_hat
sigma2_hat <- as.numeric(t(res) %*% res / n)

# evaluamos el score en (beta_hat, sigma2_hat)
score_hat <- score(beta_hat, sigma2_hat)
score_hat
# Si el score es (numéricamente) ≈ 0, indica que (beta_hat, sigma2_hat)
# es un punto crítico de la log-verosimilitud (el MLE)


```

El vector score evaluado en este punto resulta numéricamente nulo: $$s(\hat\beta, \hat\sigma^2) \approx (0,0,0,0)^t$$ lo que confirma que estamos en un punto crítico de la verosimilitud (candidato a máximo)

El score es el gradiente de la log-verosimilitud, entonces indica la dirección en que habría que modificar los parámetros para aumentar la verosimilitud. En el máximo de verosimilitud el score se anula, es decir, el modelo ajusta a los datos observados.

Como tenemos que $X_2 = 0.5*X_1 + 50$, no son realmente dos variables distitntas sino que una es combianción lineal de la otra y la matriz $X^t X$ es singular (no invertible).

Esto implica que los parámetros $\beta_1$ y $\beta_2$ no son linealmente independientes: con los datos disponibles, no podemos separar ni estimar de forma única el efecto de las emisiones y del tráfico, porque las dos variables explicativas contienen la misma información.

(esto es porque antes me ha saliod un fisher pero creo que esta mal, hay que hacerla) En términos de la matriz de información de Fisher, ésta es singular y no aporta información independiente sobre cada parámetro.

# Problema 3

Una clínica está realizando un estudio para evaluar la eficacia de un nuevo tratamiento médico para reducir la presión arterial. Se selecciona una muestra de $n = 10$ pacientes y se mide la disminución de la presión arterial (en mmHg) después de aplicar el tratamiento. El cambio en la presión arterial se modela mediante una distribución normal con media $\mu$ y varianza $\sigma^2$.

Las disminuciones observadas en la presión arterial de los pacientes son las siguientes (en mmHg):

| Paciente | Disminución (Y) |
|----------|-----------------|
| 1        | 12              |
| 2        | 8               |
| 3        | 10              |
| 4        | 15              |
| 5        | 7               |
| 6        | 9               |
| 7        | 14              |
| 8        | 11              |
| 9        | 13              |
| 10       | 6               |

Se asume que los datos provienen de una distribución normal $Y_i \sim N(\mu, \sigma^2)$.

(a) ¿Cuáles son las estimaciones de máxima verosimilitud para $\mu$ y $\sigma^2$ en este modelo?

#### Respuesta 3.a

(b) Calcula la matriz de información de Fisher para los parámetros $\mu$ y $\sigma^2$ en este modelo e interpreta los resultados.

#### Respuesta 3.b

# Problema 4

Una empresa desea comprobar si el perfil medio de sus trabajadores en cuanto a\
rendimiento ($X_1$) y satisfacción laboral ($X_2$) coincide con los valores de referencia establecidos por la dirección:

$$
\boldsymbol{\mu}_0 =
\begin{pmatrix}
70\\
7
\end{pmatrix}.
$$

Para ello, se selecciona una muestra aleatoria de tamaño $n$ de empleados y se registran sus puntuaciones en ambas variables. Se asume que el vector de observaciones

$$
\mathbf{X} = (X_1, X_2)^\top
$$

sigue una distribución normal bivariante

$$
\mathbf{X} \sim N_2(\boldsymbol{\mu}, \boldsymbol{\Sigma}),
$$

con matriz de covarianzas desconocida $\boldsymbol{\Sigma}$.

Se desea contrastar la hipótesis

$$
H_0: \boldsymbol{\mu} = \boldsymbol{\mu}_0
\quad \text{frente a} \quad
H_1: \boldsymbol{\mu} \neq \boldsymbol{\mu}_0,
$$

(a) Genera una muestra simulada de tamaño $n$ de la distribución $N_2(\boldsymbol{\mu}, \boldsymbol{\Sigma})$ (elige unos valores razonables para $\boldsymbol{\mu}$ y $\boldsymbol{\Sigma}$).

#### Respuesta 4.a

(b) Calcula la media muestral $\bar{\mathbf{X}}$, la matriz de covarianzas $\mathbf{S}$ y el estadístico de Hotelling $T^2$.

#### Respuesta 4.b

(c) Transforma $T^2$ a la escala F usando la distribución $F_{p,\,n-p}$ y calcula el p-valor del contraste para un nivel de significación $\alpha = 0.05$.

#### Respuesta 4.c

(d) Decide si se rechaza o no $H_0$.

#### Respuesta 4.d

(e) Interpreta el resultado en el contexto del problema: ¿parece que el vector medio real de la población difiere de $\boldsymbol{\mu}_0$?

#### Respuesta 4.e

# Problema 5

Un laboratorio de psicología quiere comparar el perfil cognitivo medio de dos grupos de estudiantes universitarios: los que duermen al menos 8 horas diarias y los que duermen menos de 6 horas.

A cada participante se le administran dos pruebas:

-   $X_1$: tiempo de reacción (en milisegundos, menor es mejor),
-   $X_2$: puntuación de memoria a corto plazo (de 0 a 20, mayor es mejor).

Se asume que cada grupo sigue una distribución normal bivariante con igual matriz de covarianzas $\boldsymbol{\Sigma}$:

$$
\mathbf{X}_1 \sim N_2(\boldsymbol{\mu}_1, \boldsymbol{\Sigma}), \qquad
\mathbf{X}_2 \sim N_2(\boldsymbol{\mu}_2, \boldsymbol{\Sigma}).
$$

Se desea contrastar la hipótesis

$$
H_0: \boldsymbol{\mu}_1 = \boldsymbol{\mu}_2
\quad \text{frente a} \quad
H_1: \boldsymbol{\mu}_1 \neq \boldsymbol{\mu}_2.
$$

*Datos simulados:*

| Grupo | $X_1$ (tiempo reacción, ms) | $X_2$ (memoria) |
|:-----------------------|-----------------------:|-----------------------:|
| Dormir ≥ 8h | 268, 275, 290, 260, 280, 295, 300, 285, 270, 310 | 15, 14, 17, 16, 15, 18, 17, 16, 15, 17 |
| Dormir \< 6h | 305, 320, 330, 310, 325, 335, 340, 315, 310, 330 | 12, 11, 10, 13, 12, 11, 10, 12, 11, 10 |

Contrasta la hipótesis anterior con un nivel de significación $\alpha = 0.05$ e interpreta los resultados en el contexto del problema. \#### Respuesta 5
